{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how I did a Kaggle using elasticsearch\n",
    "=====\n",
    "This code is explained in my blog article: http://melvyn.pythonanywhere.com/posts/1/  Those piece of code will allow you to reach more than 76%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyelasticsearch.client import ElasticSearch\n",
    "import random, ast, csv, requests, json, operator\n",
    "\n",
    "# Transform the ingredient list in a string\n",
    "def list_to_string_ingredients(recipes):\n",
    "    for recipe in recipes:\n",
    "        recipe['ingredients'] = ', '.join(recipe['ingredients'])\n",
    "    return recipes\n",
    "\n",
    "# Index a list of recipe in a given ES index\n",
    "def index_recipes_in_ES(index, recipes):\n",
    "    es = ElasticSearch()\n",
    "    map_id_esid = {}\n",
    "    for recipe in recipes:\n",
    "        res = es.index(index=index, doc_type='recipe', id=recipe['id'], doc=recipe)\n",
    "        if res['created'] == False:\n",
    "            print res\n",
    "\n",
    "# Build your more like this query\n",
    "def build_mlt(nb, doc_id):\n",
    "    mlt = {}\n",
    "    mlt[\"from\"] = 0\n",
    "    mlt[\"size\"] = nb\n",
    "    mlt[\"query\"] = {}\n",
    "    mlt[\"query\"][\"more_like_this\"] = {}\n",
    "    mlt[\"query\"][\"more_like_this\"][\"fields\"] = [\"ingredients\"]\n",
    "    mlt[\"query\"][\"more_like_this\"][\"like\"] = [{\"_index\" : \"test-recipe\",\"_type\" : \"recipe\",\"_id\" : doc_id}]\n",
    "    mlt[\"query\"][\"more_like_this\"][\"min_term_freq\"] = 1\n",
    "    mlt[\"query\"][\"more_like_this\"][\"max_query_terms\"] = 50\n",
    "    mlt[\"query\"][\"more_like_this\"][\"minimum_should_match\"] = \"25%\"\n",
    "    return mlt\n",
    "\n",
    "# Compute the difference between two cuisines distributions\n",
    "def diff_distribution(similar_recipes):\n",
    "    distribution = {}\n",
    "    for recipe in similar_recipes:\n",
    "        if recipe['cuisine'] in distribution:\n",
    "            distribution[recipe['cuisine']] += 1\n",
    "        else:\n",
    "            distribution[recipe['cuisine']] = 1\n",
    "    for cuisine in distribution:\n",
    "        distribution[cuisine] = distribution[cuisine] * 100 / len(similar_recipes) \n",
    "        distribution[cuisine] = distribution[cuisine] - CUISINE_DISTRIBUTION[cuisine]\n",
    "    prediction = max(distribution.iteritems(), key=operator.itemgetter(1))[0]\n",
    "    return prediction\n",
    "\n",
    "# Extract as a list the result from Elasticsearch\n",
    "def extract_from_json(json):\n",
    "    hits = json['hits']['hits']\n",
    "    recipes = [hit['_source'] for hit in hits]\n",
    "    return recipes\n",
    "\n",
    "# Send the request to elasticsearch and extract the result\n",
    "def get_similar(nb, doc_id):\n",
    "    mlt = build_mlt(nb, doc_id)\n",
    "    response = requests.post(\"http://localhost:9200/train-recipe/recipe/_search\", data=json.dumps(mlt))\n",
    "    similar_recipes = extract_from_json(json.loads(response.text))\n",
    "    return similar_recipes\n",
    "\n",
    "# Retrieve a specific document givent its ID\n",
    "def get_document_by_id(index, doc_id):\n",
    "    es = ElasticSearch()\n",
    "    response = es.get(index=index, doc_type='recipe', id=doc_id)\n",
    "    return response['_source']\n",
    "\n",
    "# Launch a prediction on a list of recipes, with a given prediction function, and a number of similar document required\n",
    "def predict(recipes_to_predict, predict_origin, mlt_nb=100):\n",
    "    predictions = []\n",
    "    for recipe in recipes_to_predict:\n",
    "        similar_recipes = get_similar(mlt_nb, recipe['id'])\n",
    "        prediction = predict_origin(similar_recipes)\n",
    "        predictions.append((prediction, recipe['id']))\n",
    "    return predictions\n",
    "\n",
    "# Transform a set of recipe predicted into a CSV ready to drop on Kaggle\n",
    "def to_csv(predictions):\n",
    "    f = csv.writer(open(\"results.csv\", \"wb+\"))\n",
    "    f.writerow([\"id\", \"cuisine\"])\n",
    "    for prediction in predictions:\n",
    "        f.writerow([prediction[1], prediction[0]])\n",
    "\n",
    "# Compute the cuisine distribution of list of recipe\n",
    "def get_cuisine_distribution(recipes):\n",
    "    cuisine_distribution = {}\n",
    "    for recipe in recipes:\n",
    "        if recipe['cuisine'] in cuisine_distribution:\n",
    "            cuisine_distribution[recipe['cuisine']] += 1\n",
    "        else:\n",
    "            cuisine_distribution[recipe['cuisine']] = 1\n",
    "    for cuisine in cuisine_distribution:\n",
    "        cuisine_distribution[cuisine] =  float(cuisine_distribution[cuisine])/float(len(recipes))\n",
    "    return cuisine_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_file = open('data/train.json', 'r')\n",
    "train_recipes = ast.literal_eval(data_file.read())\n",
    "data_file = open('data/test.json', 'r')\n",
    "test_recipes = ast.literal_eval(data_file.read())\n",
    "\n",
    "CUISINE_DISTRIBUTION = get_cuisine_distribution(train_recipes)\n",
    "\n",
    "train_recipes = list_to_string_ingredients(train_recipes)\n",
    "test_recipes = list_to_string_ingredients(test_recipes)\n",
    "\n",
    "index_recipes_in_ES('train-recipe', train_recipes)\n",
    "index_recipes_in_ES('test-recipe', test_recipes)\n",
    "\n",
    "results = predict(test_recipes, diff_distribution, 15)\n",
    "to_csv(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part I provide some code allowing you to split your training test in 2 parts to be able to optimize your parameters\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute your sucess rate\n",
    "def get_result_test(results, random_recipes_test):\n",
    "    succes = []\n",
    "    fail = []\n",
    "    for result in results:\n",
    "        real_cuisine = get_document_by_id('test-recipe', result[1])\n",
    "        predict_cuisine = result[0]\n",
    "        if real_cuisine['cuisine'] == predict_cuisine:\n",
    "            succes.append(real_cuisine)\n",
    "        else:\n",
    "            fail.append(real_cuisine)\n",
    "    succes = Result_percentage(succes, float(len(random_recipes_test))) \n",
    "    fail = Result_percentage(fail, float(len(random_recipes_test))) \n",
    "    return succes, fail\n",
    "\n",
    "class Result_percentage:\n",
    "    def __init__(self, recipes, length_test):\n",
    "        distribution = {}\n",
    "        for recipe in recipes:\n",
    "            cuisine = recipe['cuisine']\n",
    "            if cuisine not in distribution:\n",
    "                distribution[cuisine] = 1\n",
    "            else:\n",
    "                distribution[cuisine] += 1\n",
    "        for cuisine in distribution:\n",
    "            distribution[cuisine] = distribution[cuisine] * 100 / float(len(recipes))\n",
    "        self.distribution = distribution\n",
    "        self.percentage = len(recipes) / length_test * 100     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_file = open('data/train.json', 'r')\n",
    "train_recipes = ast.literal_eval(data_file.read())\n",
    "data_file = open('data/test.json', 'r')\n",
    "test_recipes = ast.literal_eval(data_file.read())\n",
    "\n",
    "nb_train_recipes = len(train_recipes)\n",
    "\n",
    "random_recipes_test = []\n",
    "for generated_test_nb in range(0, nb_train_recipes/3):\n",
    "    recipe = random.choice(train_recipes)\n",
    "    while recipe in random_recipes_test:\n",
    "        recipe = random.choice(train_recipes)\n",
    "    random_recipes_test.append(recipe)\n",
    "\n",
    "random_recipes_train = []\n",
    "for recipe in train_recipes:\n",
    "    if recipe not in random_recipes_test:\n",
    "        random_recipes_train.append(recipe)\n",
    "        \n",
    "CUISINE_DISTRIBUTION = get_cuisine_distribution(random_recipes_train)\n",
    "\n",
    "random_recipes_train = list_to_string_ingredients(random_recipes_train)\n",
    "random_recipes_test = list_to_string_ingredients(random_recipes_test)\n",
    "\n",
    "index_recipes_in_ES('train-recipe', random_recipes_train)\n",
    "index_recipes_in_ES('test-recipe', random_recipes_test)\n",
    "\n",
    "results = predict(random_recipes_test, diff_distribution, 15)\n",
    "score = get_result_test(results, random_recipes_test)\n",
    "\n",
    "print score[0].distribution\n",
    "print score[0].percentage, \"Success\"\n",
    "print \"--------------\"\n",
    "print score[1].distribution\n",
    "print score[1].percentage, \"Failure\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
