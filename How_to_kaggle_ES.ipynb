{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyelasticsearch.client import ElasticSearch\n",
    "import ast, csv, requests, json, operator\n",
    "\n",
    "def list_to_string_ingredients(recipes):\n",
    "    for recipe in recipes:\n",
    "        recipe['ingredients'] = ', '.join(recipe['ingredients'])\n",
    "    return recipes\n",
    "\n",
    "def index_recipes_in_ES(index, recipes):\n",
    "    es = ElasticSearch()\n",
    "    map_id_esid = {}\n",
    "    for recipe in recipes:\n",
    "        res = es.index(index=index, doc_type='recipe', id=recipe['id'], doc=recipe)\n",
    "        if res['created'] == False:\n",
    "            print res\n",
    "\n",
    "def build_mlt(nb, doc_id):\n",
    "    mlt = {}\n",
    "    mlt[\"from\"] = 0\n",
    "    mlt[\"size\"] = nb\n",
    "    mlt[\"query\"] = {}\n",
    "    mlt[\"query\"][\"more_like_this\"] = {}\n",
    "    mlt[\"query\"][\"more_like_this\"][\"fields\"] = [\"ingredients\"]\n",
    "    mlt[\"query\"][\"more_like_this\"][\"like\"] = [{\"_index\" : \"test-recipe\",\"_type\" : \"recipe\",\"_id\" : doc_id}]\n",
    "    mlt[\"query\"][\"more_like_this\"][\"min_term_freq\"] = 1\n",
    "    mlt[\"query\"][\"more_like_this\"][\"max_query_terms\"] = 50\n",
    "    mlt[\"query\"][\"more_like_this\"][\"minimum_should_match\"] = \"25%\"\n",
    "    return mlt\n",
    "\n",
    "def diff_distribution(similar_recipes):\n",
    "    distribution = {}\n",
    "    for recipe in similar_recipes:\n",
    "        if recipe['cuisine'] in distribution:\n",
    "            distribution[recipe['cuisine']] += 1\n",
    "        else:\n",
    "            distribution[recipe['cuisine']] = 1\n",
    "    for cuisine in distribution:\n",
    "        distribution[cuisine] = distribution[cuisine] * 100 / len(similar_recipes) \n",
    "        distribution[cuisine] = distribution[cuisine] - CUISINE_DISTRIBUTION[cuisine]\n",
    "    prediction = max(distribution.iteritems(), key=operator.itemgetter(1))[0]\n",
    "    return prediction\n",
    "\n",
    "def extract_from_json(json):\n",
    "    hits = json['hits']['hits']\n",
    "    recipes = [hit['_source'] for hit in hits]\n",
    "    return recipes\n",
    "\n",
    "\n",
    "def get_similar(nb, doc_id):\n",
    "    mlt = build_mlt(nb, doc_id)\n",
    "    response = requests.post(\"http://localhost:9200/train-recipe/recipe/_search\", data=json.dumps(mlt))\n",
    "    similar_recipes = extract_from_json(json.loads(response.text))\n",
    "    return similar_recipes\n",
    "\n",
    "def get_document_by_id(index, doc_id):\n",
    "    es = ElasticSearch()\n",
    "    response = es.get(index=index, doc_type='recipe', id=doc_id)\n",
    "    return response['_source']\n",
    "\n",
    "def predict(recipes_to_predict, predict_origin, mlt_nb=100):\n",
    "    predictions = []\n",
    "    for recipe in recipes_to_predict:\n",
    "        similar_recipes = get_similar(mlt_nb, recipe['id'])\n",
    "        prediction = predict_origin(similar_recipes)\n",
    "        predictions.append((prediction, recipe['id']))\n",
    "    return predictions\n",
    "\n",
    "def to_csv(predictions):\n",
    "    f = csv.writer(open(\"results.csv\", \"wb+\"))\n",
    "    f.writerow([\"id\", \"cuisine\"])\n",
    "    for prediction in predictions:\n",
    "        f.writerow([prediction[1], prediction[0]])\n",
    "\n",
    "def get_cuisine_distribution(recipes):\n",
    "    cuisine_distribution = {}\n",
    "    for recipe in recipes:\n",
    "        if recipe['cuisine'] in cuisine_distribution:\n",
    "            cuisine_distribution[recipe['cuisine']] += 1\n",
    "        else:\n",
    "            cuisine_distribution[recipe['cuisine']] = 1\n",
    "    for cuisine in cuisine_distribution:\n",
    "        cuisine_distribution[cuisine] =  float(cuisine_distribution[cuisine])/float(len(recipes))\n",
    "    return cuisine_distribution\n",
    "\n",
    "data_file = open('data/train.json', 'r')\n",
    "train_recipes = ast.literal_eval(data_file.read())\n",
    "data_file = open('data/test.json', 'r')\n",
    "test_recipes = ast.literal_eval(data_file.read())\n",
    "\n",
    "CUISINE_DISTRIBUTION = get_cuisine_distribution(train_recipes)\n",
    "\n",
    "train_recipes = list_to_string_ingredients(train_recipes)\n",
    "test_recipes = list_to_string_ingredients(test_recipes)\n",
    "\n",
    "index_recipes_in_ES('train-recipe', train_recipes)\n",
    "index_recipes_in_ES('test-recipe', test_recipes)\n",
    "\n",
    "results = predict(test_recipes, diff_distribution, 15)\n",
    "to_csv(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
